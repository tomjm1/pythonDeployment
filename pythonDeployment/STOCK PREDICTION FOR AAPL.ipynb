{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ideal-minnesota",
   "metadata": {},
   "source": [
    "# IMPORT NECESSARY MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "generic-pioneer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "### Data Collection\n",
    "import pandas_datareader as pdr\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fitting-judgment",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create the Stacked LSTM model\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "from keras.models import load_model\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "british-joint",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib,json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "destroyed-powell",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "popular-treatment",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=\"USE TIINGO TO GET THE API KEY AND PASTE IT HERE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "specialized-package",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "equal-vocabulary",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA AND SAVE IT TO CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "acquired-blood",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pdr.get_data_tiingo('AAPL', api_key=key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "premier-mercury",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "streaming-straight",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "mineral-relation",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('AAPL.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "critical-venice",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df.reset_index()['close']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "actual-event",
   "metadata": {},
   "outputs": [],
   "source": [
    "### LSTM are sensitive to the scale of the data. so we apply MinMax scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "atlantic-trinidad",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=MinMaxScaler(feature_range=(0,1))\n",
    "df1=scaler.fit_transform(np.array(df1).reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "administrative-layer",
   "metadata": {},
   "outputs": [],
   "source": [
    "##splitting dataset into train and test split\n",
    "training_size=int(len(df1)*0.65)\n",
    "test_size=len(df1)-training_size\n",
    "train_data,test_data=df1[0:training_size,:],df1[training_size:len(df1),:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "atomic-leader",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert an array of values into a dataset matrix\n",
    "def create_dataset(dataset, time_step=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-time_step-1):\n",
    "        a = dataset[i:(i+time_step), 0]   ###i=0, 0,1,2,3-----99   100 \n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + time_step, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "severe-tender",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape into X=t,t+1,t+2,t+3 and Y=t+4\n",
    "time_step = 100\n",
    "X_train, y_train = create_dataset(train_data, time_step)\n",
    "X_test, ytest = create_dataset(test_data, time_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "numerical-authentication",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape input to be [samples, time steps, features] which is required for LSTM\n",
    "X_train =X_train.reshape(X_train.shape[0],X_train.shape[1] , 1)\n",
    "X_test = X_test.reshape(X_test.shape[0],X_test.shape[1] , 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "furnished-iceland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "unable-samba",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=Sequential()\n",
    "model.add(LSTM(50,return_sequences=True,input_shape=(100,1)))\n",
    "model.add(LSTM(50,return_sequences=True))\n",
    "model.add(LSTM(50))\n",
    "model.add(Dense(1))\n",
    "model.compile(loss='mean_squared_error',optimizer='adam')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "crude-priest",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "12/12 [==============================] - 3s 274ms/step - loss: 0.0083 - val_loss: 0.0510\n",
      "Epoch 2/100\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 0.0020 - val_loss: 0.0245\n",
      "Epoch 3/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 8.7570e-04 - val_loss: 0.0213\n",
      "Epoch 4/100\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 4.7394e-04 - val_loss: 0.0200\n",
      "Epoch 5/100\n",
      "12/12 [==============================] - 2s 144ms/step - loss: 4.3308e-04 - val_loss: 0.0196\n",
      "Epoch 6/100\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 3.9733e-04 - val_loss: 0.0190\n",
      "Epoch 7/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 3.9491e-04 - val_loss: 0.0185\n",
      "Epoch 8/100\n",
      "12/12 [==============================] - 2s 139ms/step - loss: 3.9229e-04 - val_loss: 0.0182\n",
      "Epoch 9/100\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 3.8621e-04 - val_loss: 0.0174\n",
      "Epoch 10/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 3.5503e-04 - val_loss: 0.0170\n",
      "Epoch 11/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 3.2984e-04 - val_loss: 0.0164\n",
      "Epoch 12/100\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 3.1501e-04 - val_loss: 0.0159\n",
      "Epoch 13/100\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 2.9771e-04 - val_loss: 0.0155\n",
      "Epoch 14/100\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 2.9257e-04 - val_loss: 0.0157\n",
      "Epoch 15/100\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 2.7659e-04 - val_loss: 0.0153\n",
      "Epoch 16/100\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 2.9881e-04 - val_loss: 0.0159\n",
      "Epoch 17/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 2.6968e-04 - val_loss: 0.0150\n",
      "Epoch 18/100\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 2.3949e-04 - val_loss: 0.0150\n",
      "Epoch 19/100\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 2.4553e-04 - val_loss: 0.0157\n",
      "Epoch 20/100\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 2.4300e-04 - val_loss: 0.0154\n",
      "Epoch 21/100\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 2.3058e-04 - val_loss: 0.0148\n",
      "Epoch 22/100\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 2.2931e-04 - val_loss: 0.0143\n",
      "Epoch 23/100\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 2.7131e-04 - val_loss: 0.0164\n",
      "Epoch 24/100\n",
      "12/12 [==============================] - 2s 145ms/step - loss: 2.9908e-04 - val_loss: 0.0136\n",
      "Epoch 25/100\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 2.2584e-04 - val_loss: 0.0139\n",
      "Epoch 26/100\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 2.3006e-04 - val_loss: 0.0140\n",
      "Epoch 27/100\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 2.1506e-04 - val_loss: 0.0136\n",
      "Epoch 28/100\n",
      "12/12 [==============================] - 2s 143ms/step - loss: 2.1253e-04 - val_loss: 0.0143\n",
      "Epoch 29/100\n",
      "12/12 [==============================] - 2s 142ms/step - loss: 2.0344e-04 - val_loss: 0.0136\n",
      "Epoch 30/100\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 2.1817e-04 - val_loss: 0.0130\n",
      "Epoch 31/100\n",
      "12/12 [==============================] - 2s 141ms/step - loss: 2.0816e-04 - val_loss: 0.0134\n",
      "Epoch 32/100\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 1.9651e-04 - val_loss: 0.0140\n",
      "Epoch 33/100\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 2.0724e-04 - val_loss: 0.0130\n",
      "Epoch 34/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.9635e-04 - val_loss: 0.0133\n",
      "Epoch 35/100\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 2.4090e-04 - val_loss: 0.0123\n",
      "Epoch 36/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 2.0669e-04 - val_loss: 0.0120\n",
      "Epoch 37/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.9211e-04 - val_loss: 0.0115\n",
      "Epoch 38/100\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 1.8929e-04 - val_loss: 0.0125\n",
      "Epoch 39/100\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 1.9083e-04 - val_loss: 0.0118\n",
      "Epoch 40/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.8098e-04 - val_loss: 0.0113\n",
      "Epoch 41/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.7833e-04 - val_loss: 0.0115\n",
      "Epoch 42/100\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 1.8263e-04 - val_loss: 0.0109\n",
      "Epoch 43/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.8456e-04 - val_loss: 0.0115\n",
      "Epoch 44/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.9361e-04 - val_loss: 0.0109\n",
      "Epoch 45/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.7307e-04 - val_loss: 0.0105\n",
      "Epoch 46/100\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 1.6924e-04 - val_loss: 0.0106\n",
      "Epoch 47/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.7264e-04 - val_loss: 0.0104\n",
      "Epoch 48/100\n",
      "12/12 [==============================] - 2s 146ms/step - loss: 1.7058e-04 - val_loss: 0.0102\n",
      "Epoch 49/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.7450e-04 - val_loss: 0.0098\n",
      "Epoch 50/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 2.0677e-04 - val_loss: 0.0106\n",
      "Epoch 51/100\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 1.7339e-04 - val_loss: 0.0098\n",
      "Epoch 52/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.9500e-04 - val_loss: 0.0101\n",
      "Epoch 53/100\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 1.6743e-04 - val_loss: 0.0097\n",
      "Epoch 54/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.6485e-04 - val_loss: 0.0097\n",
      "Epoch 55/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.6108e-04 - val_loss: 0.0104\n",
      "Epoch 56/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.6646e-04 - val_loss: 0.0107\n",
      "Epoch 57/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.6398e-04 - val_loss: 0.0092\n",
      "Epoch 58/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.7197e-04 - val_loss: 0.0096\n",
      "Epoch 59/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.6598e-04 - val_loss: 0.0102\n",
      "Epoch 60/100\n",
      "12/12 [==============================] - 2s 148ms/step - loss: 1.9472e-04 - val_loss: 0.0089\n",
      "Epoch 61/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.6342e-04 - val_loss: 0.0093\n",
      "Epoch 62/100\n",
      "12/12 [==============================] - 2s 147ms/step - loss: 1.4734e-04 - val_loss: 0.0092\n",
      "Epoch 63/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.5109e-04 - val_loss: 0.0088\n",
      "Epoch 64/100\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 1.4900e-04 - val_loss: 0.0089\n",
      "Epoch 65/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.5335e-04 - val_loss: 0.0086\n",
      "Epoch 66/100\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 1.5205e-04 - val_loss: 0.0083\n",
      "Epoch 67/100\n",
      "12/12 [==============================] - 2s 176ms/step - loss: 1.7373e-04 - val_loss: 0.0093\n",
      "Epoch 68/100\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 1.5758e-04 - val_loss: 0.0081\n",
      "Epoch 69/100\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 1.5957e-04 - val_loss: 0.0082\n",
      "Epoch 70/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.4084e-04 - val_loss: 0.0088\n",
      "Epoch 71/100\n",
      "12/12 [==============================] - 2s 163ms/step - loss: 1.4121e-04 - val_loss: 0.0082\n",
      "Epoch 72/100\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 1.4187e-04 - val_loss: 0.0085\n",
      "Epoch 73/100\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 1.3390e-04 - val_loss: 0.0082\n",
      "Epoch 74/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.3909e-04 - val_loss: 0.0082\n",
      "Epoch 75/100\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 1.4405e-04 - val_loss: 0.0085\n",
      "Epoch 76/100\n",
      "12/12 [==============================] - 2s 160ms/step - loss: 1.5239e-04 - val_loss: 0.0079\n",
      "Epoch 77/100\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 1.5433e-04 - val_loss: 0.0079\n",
      "Epoch 78/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 2s 154ms/step - loss: 1.7104e-04 - val_loss: 0.0076\n",
      "Epoch 79/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.3170e-04 - val_loss: 0.0083\n",
      "Epoch 80/100\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 1.4567e-04 - val_loss: 0.0078\n",
      "Epoch 81/100\n",
      "12/12 [==============================] - 2s 159ms/step - loss: 1.2350e-04 - val_loss: 0.0076\n",
      "Epoch 82/100\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 1.2793e-04 - val_loss: 0.0074\n",
      "Epoch 83/100\n",
      "12/12 [==============================] - 2s 152ms/step - loss: 1.3353e-04 - val_loss: 0.0076\n",
      "Epoch 84/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.3446e-04 - val_loss: 0.0072\n",
      "Epoch 85/100\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 1.2112e-04 - val_loss: 0.0076\n",
      "Epoch 86/100\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 1.3062e-04 - val_loss: 0.0071\n",
      "Epoch 87/100\n",
      "12/12 [==============================] - 2s 157ms/step - loss: 1.6609e-04 - val_loss: 0.0078\n",
      "Epoch 88/100\n",
      "12/12 [==============================] - 2s 156ms/step - loss: 1.5238e-04 - val_loss: 0.0069\n",
      "Epoch 89/100\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 1.2922e-04 - val_loss: 0.0070\n",
      "Epoch 90/100\n",
      "12/12 [==============================] - 2s 155ms/step - loss: 1.1737e-04 - val_loss: 0.0071\n",
      "Epoch 91/100\n",
      "12/12 [==============================] - 2s 161ms/step - loss: 1.2474e-04 - val_loss: 0.0068\n",
      "Epoch 92/100\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 1.2120e-04 - val_loss: 0.0070\n",
      "Epoch 93/100\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 1.2944e-04 - val_loss: 0.0070\n",
      "Epoch 94/100\n",
      "12/12 [==============================] - 2s 150ms/step - loss: 1.2893e-04 - val_loss: 0.0066\n",
      "Epoch 95/100\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 1.1563e-04 - val_loss: 0.0067\n",
      "Epoch 96/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.1776e-04 - val_loss: 0.0064\n",
      "Epoch 97/100\n",
      "12/12 [==============================] - 2s 153ms/step - loss: 1.1900e-04 - val_loss: 0.0068\n",
      "Epoch 98/100\n",
      "12/12 [==============================] - 2s 149ms/step - loss: 1.1478e-04 - val_loss: 0.0066\n",
      "Epoch 99/100\n",
      "12/12 [==============================] - 2s 151ms/step - loss: 1.1197e-04 - val_loss: 0.0063\n",
      "Epoch 100/100\n",
      "12/12 [==============================] - 2s 154ms/step - loss: 1.0714e-04 - val_loss: 0.0061\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(X_train,y_train,validation_data=(X_test,ytest),epochs=100,batch_size=64,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "upset-pacific",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save('my_model2.h5')  # creates a HDF5 file 'my_model.h5'\n",
    "#del model  # deletes the existing model\n",
    "# returns a compiled model\n",
    "# identical to the previous one\n",
    "model1 = load_model('my_model2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "needed-morning",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Lets Do the prediction and check performance metrics\n",
    "train_predict=model1.predict(X_train)\n",
    "test_predict=model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "green-georgia",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.04504424],\n",
       "       [0.04555406],\n",
       "       [0.04586112],\n",
       "       [0.04603073],\n",
       "       [0.04598634]], dtype=float32)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "hungarian-athletics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.4331462 ],\n",
       "       [0.4351221 ],\n",
       "       [0.43708438],\n",
       "       [0.43729502],\n",
       "       [0.43540728]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "divine-passion",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Transformback to original form\n",
    "train_predict=scaler.inverse_transform(train_predict)\n",
    "test_predict=scaler.inverse_transform(test_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "beneficial-hands",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[109.06714 ],\n",
       "       [109.2791  ],\n",
       "       [109.40676 ],\n",
       "       [109.47727 ],\n",
       "       [109.458824]], dtype=float32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "amino-heading",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[270.42053],\n",
       "       [271.24203],\n",
       "       [272.05783],\n",
       "       [272.1454 ],\n",
       "       [271.36057]], dtype=float32)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_predict[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brown-absence",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
